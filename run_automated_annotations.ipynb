{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "157ebc48-e88f-4780-bd94-0029e9fdac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d5452f8-1905-409f-aadf-2ec5207732df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processed .wav files: 2354\n"
     ]
    }
   ],
   "source": [
    "# check for numbers of completed sessions\n",
    "tag = 'base-whisperx'\n",
    "model_out = 'whisperx_out'\n",
    "outputs = glob.glob(f'/home1/rdehaan/projects/automated_annotation/results/{tag}/data/eeg/scalp/ltp/ltpFR2/*/session_*/{model_out}/*.csv')\n",
    "print('Number of processed .wav files:', len(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1036882c-f976-4739-8204-223279ac4df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load session index with environment that has cmlreaders (can't install cmlreaders for py3.10)\n",
    "if sys.version.split(' ')[0] >= '3.10' and sys.version.split(' ')[0] < '3.11':\n",
    "    exps = ['ltpFR2']\n",
    "    index_df = pd.read_csv(f'session_index_{\"-\".join(exps)}.csv')\n",
    "else:\n",
    "    import cmlreaders as cml\n",
    "\n",
    "    index_df = cml.get_data_index('ltp')\n",
    "    print('Available experiments:\\n', index_df.experiment.unique())\n",
    "    index_df = index_df.query('experiment in @exps')\n",
    "    index_df.to_csv(f'session_index_{\"-\".join(exps)}.csv')\n",
    "\n",
    "    load example session events\n",
    "    sess_df = index_df.iloc[25]\n",
    "    r = cml.CMLReader(subject=sess_df.subject, session=sess_df.session, experiment=sess_df.experiment)\n",
    "    evs = r.load('events')\n",
    "    print('Event types:\\n', evs.type.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db139d3d-bbfb-4cfb-9651-fcc3a122070b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sessions available: 1125\n",
      "val sessions available: 536\n",
      "test sessions available: 808\n",
      "Example session directories:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/data/eeg/scalp/ltp/ltpFR2/LTP299/session_5',\n",
       " '/data/eeg/scalp/ltp/ltpFR2/LTP334/session_17',\n",
       " '/data/eeg/scalp/ltp/ltpFR2/LTP317/session_13',\n",
       " '/data/eeg/scalp/ltp/ltpFR2/LTP358/session_6',\n",
       " '/data/eeg/scalp/ltp/ltpFR2/LTP242/session_0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_folders_containing_files(directory=\".\", pattern=\"*\"):\n",
    "    \"\"\"\n",
    "    Get folders containing files that match the specified glob pattern.\n",
    "    \n",
    "    Parameters:\n",
    "    - directory (str): The starting directory for the search.\n",
    "    - pattern (str): The glob pattern to search for. e.g. \"*.wav\", \"audio_*.mp3\", \"document_?.txt\", etc.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of folders containing files that match the glob pattern.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get all the files matching the pattern in the directory and its sub-directories.\n",
    "    matching_files = glob.glob(os.path.join(directory, '**', pattern), recursive=True)\n",
    "    \n",
    "    # Get the unique directories containing the files that match the pattern.\n",
    "    folders = set(os.path.dirname(file) for file in matching_files)\n",
    "\n",
    "    return list(folders)\n",
    "\n",
    "\n",
    "# build train-val-test split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "random_seed = 42\n",
    "train_prop = 0.5\n",
    "val_prop = 0.2\n",
    "test_prop = 0.3\n",
    "assert train_prop + val_prop + test_prop == 1\n",
    "\n",
    "index_df['split_group'] = index_df['subject'] + '_' + index_df['experiment']\n",
    "train_val_idx, test_idx = next(GroupShuffleSplit(train_size=train_prop + val_prop, \n",
    "                                                 test_size=test_prop, \n",
    "                                                 random_state=random_seed).split(index_df,\n",
    "                                                                                 groups=index_df['split_group']))\n",
    "train_idx, val_idx = next(GroupShuffleSplit(train_size=train_prop / (train_prop + val_prop),\n",
    "                                            test_size=val_prop / (train_prop + val_prop),\n",
    "                                            random_state=random_seed + 1).split(index_df.iloc[train_val_idx],\n",
    "                                                                                groups=index_df.iloc[train_val_idx]['split_group']))\n",
    "index_dfs = {'train': index_df.iloc[train_val_idx].iloc[train_idx],\n",
    "             'val': index_df.iloc[train_val_idx].iloc[val_idx],\n",
    "             'test': index_df.iloc[test_idx]}\n",
    "\n",
    "# assert no overlap across splits\n",
    "assert not set(index_dfs['train'].split_group).intersection(index_dfs['test'].split_group)\n",
    "assert not set(index_dfs['train'].split_group).intersection(index_dfs['val'].split_group)\n",
    "assert not set(index_dfs['val'].split_group).intersection(index_dfs['test'].split_group)\n",
    "\n",
    "# obtain session data directories\n",
    "input_dirs = {'train': list(), 'val': list(), 'test': list()}\n",
    "for exp in exps:\n",
    "    # get all session directories containing .wav files\n",
    "    wav_dirs = get_folders_containing_files(pattern=\"0.wav\", directory=f'/data/eeg/scalp/ltp/{exp}')\n",
    "    # drop sessions marked bad\n",
    "    wav_dirs = {d for d in wav_dirs if not 'bad' in d.lower()}\n",
    "    for split in input_dirs:\n",
    "        # keep only sessions that were processed through event_creation for quality control\n",
    "        exp_dirs = {f'/data/eeg/scalp/ltp/{sess.experiment}/{sess.subject}/session_{sess.session}' \n",
    "                    for _, sess in index_dfs[split].iterrows()}\n",
    "        exp_dirs = exp_dirs.intersection(wav_dirs)\n",
    "        input_dirs[split].extend(list(exp_dirs))\n",
    "\n",
    "for split in input_dirs:\n",
    "    print(f'{split} sessions available: {len(input_dirs[split])}')\n",
    "print('Example session directories:')\n",
    "input_dirs['train'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74ba78ae-53c1-408f-81b6-1e2779f3a2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home1/rdehaan/projects/automated_annotation'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efdd4437-9755-4807-9211-8b35b706c3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain session processing output directories\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "tags = ['base-whisperx']\n",
    "all_output_dirs = dict()\n",
    "all_input_dirs = dict()\n",
    "output_dirs = dict()\n",
    "\n",
    "for tag in tags:\n",
    "    output_dirs[tag] = dict()\n",
    "    all_input_dirs[tag] = list()\n",
    "    all_output_dirs[tag] = list()\n",
    "    for split in input_dirs:\n",
    "        output_dirs[tag][split] = [os.getcwd() + f'/results/{tag}' + d if os.path.isabs(d) else os.path.join('results', tag, d)\n",
    "                                   for d in input_dirs[split]]\n",
    "        all_output_dirs[tag].extend(output_dirs[tag][split])\n",
    "        all_input_dirs[tag].extend(input_dirs[split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be79aa53-6976-4ff9-b641-03af041ccb65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2469"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_input_dirs[tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a087aadf-77a2-42b4-af37-1c4f014659cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home1/rdehaan/projects/automated_annotation'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# os.chdir('/home1/rdehaan/projects/automated_annotation')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "686ded3f-1650-4dfb-b245-e73ac39cfd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/eeg/scalp/ltp/ltpFR2/LTP299/session_5'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_input_dirs[tag][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a2d2a3c-409c-4834-aa15-391e3444c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('input_dirs.pkl', 'wb') as f:\n",
    "    pickle.dump(all_input_dirs, f)\n",
    "with open('output_dirs.pkl', 'wb') as f:\n",
    "    pickle.dump(all_output_dirs, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb3f2a5e-8983-4b51-af0d-9112c45c4edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting run_whisperx with\n",
      "/data/eeg/scalp/ltp/ltpFR2/LTP299/session_5 /home1/rdehaan/projects/automated_annotation/results/base-whisperx/data/eeg/scalp/ltp/ltpFR2/LTP299/session_5\n",
      "\n",
      "\n",
      "====== Device type : cpu ======\n",
      "No language specified, language will be first be detected for each audio file (increases inference time).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.1.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../.cache/torch/whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.0.0. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.1. Bad things might happen unless you revert torch to 1.x.\n",
      "WAV files found:\n",
      "\n",
      "\n",
      "Processing 16.wav...\n",
      "loading audio /data/eeg/scalp/ltp/ltpFR2/LTP299/session_5/16.wav\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ffmpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautomated_annot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_whisperx\n\u001b[0;32m----> 2\u001b[0m \u001b[43mrun_whisperx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_input_dirs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_output_dirs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/automated_annotation/automated_annot.py:47\u001b[0m, in \u001b[0;36mrun_whisperx\u001b[0;34m(in_dir, out_dir, use_gpu)\u001b[0m\n\u001b[1;32m     45\u001b[0m filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(in_dir, file)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloading audio\u001b[39m\u001b[38;5;124m'\u001b[39m, filepath)\n\u001b[0;32m---> 47\u001b[0m audio \u001b[38;5;241m=\u001b[39m \u001b[43mwhisperx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloaded audio\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     49\u001b[0m result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtranscribe(audio, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "File \u001b[0;32m~/.conda/envs/annotate/lib/python3.10/site-packages/whisperx/audio.py:46\u001b[0m, in \u001b[0;36mload_audio\u001b[0;34m(file, sr)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03mOpen an audio file and read as mono waveform, resampling as necessary\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03mA NumPy array containing the audio waveform, in float32 dtype.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# This launches a subprocess to decode audio while down-mixing and resampling as necessary.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# Requires the ffmpeg CLI and `ffmpeg-python` package to be installed.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     out, _ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 46\u001b[0m         \u001b[43mffmpeg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ms16le\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macodec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpcm_s16le\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mffmpeg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-nostdin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_stdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_stderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     )\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ffmpeg\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load audio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/annotate/lib/python3.10/site-packages/ffmpeg/_run.py:313\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(stream_spec, cmd, capture_stdout, capture_stderr, input, quiet, overwrite_output)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;129m@output_operator\u001b[39m()\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\n\u001b[1;32m    291\u001b[0m     stream_spec,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m     overwrite_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    298\u001b[0m ):\n\u001b[1;32m    299\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Invoke ffmpeg for the supplied node graph.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03m    Returns: (out, err) tuple containing captured stdout and stderr data.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m     process \u001b[38;5;241m=\u001b[39m \u001b[43mrun_async\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipe_stdin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipe_stdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_stdout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipe_stderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_stderr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     out, err \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    323\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n",
      "File \u001b[0;32m~/.conda/envs/annotate/lib/python3.10/site-packages/ffmpeg/_run.py:284\u001b[0m, in \u001b[0;36mrun_async\u001b[0;34m(stream_spec, cmd, pipe_stdin, pipe_stdout, pipe_stderr, quiet, overwrite_output)\u001b[0m\n\u001b[1;32m    282\u001b[0m stdout_stream \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPIPE \u001b[38;5;28;01mif\u001b[39;00m pipe_stdout \u001b[38;5;129;01mor\u001b[39;00m quiet \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    283\u001b[0m stderr_stream \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPIPE \u001b[38;5;28;01mif\u001b[39;00m pipe_stderr \u001b[38;5;129;01mor\u001b[39;00m quiet \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstdin_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstdout_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstderr_stream\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/annotate/lib/python3.10/subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m~/.conda/envs/annotate/lib/python3.10/subprocess.py:1863\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1862\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ffmpeg'"
     ]
    }
   ],
   "source": [
    "from automated_annot import run_whisperx\n",
    "run_whisperx(all_input_dirs[tag][0], all_output_dirs[tag][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60b8e567-dbbc-48fe-b2ee-dbfb5cd84f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique port for rdehaan is 51474\n",
      "{'dashboard_address': ':51474'}\n",
      "To view the dashboard, run: \n",
      "`ssh -fN rdehaan@rhino2.psych.upenn.edu -L 8000:192.168.86.140:44068` in your local computer's terminal (NOT rhino) \n",
      "and then navigate to localhost:8000 in your browser\n",
      "starting run_whisperx with\n",
      "/data/eeg/scalp/ltp/ltpFR2/LTP301/session_4 /home1/rdehaan/projects/automated_annotation/results/base-whisperx/data/eeg/scalp/ltp/ltpFR2/LTP301/session_4\n",
      "\n",
      "\n",
      "====== Device type : cpu ======\n",
      "WAV files found:\n",
      "\n",
      "\n",
      "Processing 16.wav...\n",
      "loading audio /data/eeg/scalp/ltp/ltpFR2/LTP301/session_4/16.wav\n"
     ]
    }
   ],
   "source": [
    "from automated_annot import run_whisperx\n",
    "from cmldask import CMLDask\n",
    "from dask.distributed import wait\n",
    "\n",
    "tag = 'base-whisperx'\n",
    "dask_args = {'job_name': 'auto_annotate', 'memory_per_job': \"9GB\", 'max_n_jobs': 35,\n",
    "            'death_timeout': 600, 'extra': ['--no-dashboard'], 'log_directory': 'logs'}\n",
    "\n",
    "client = CMLDask.new_dask_client_slurm(**dask_args)\n",
    "dask_inputs = [all_input_dirs[tag][:1], all_output_dirs[tag][:1]]\n",
    "futures = client.map(run_whisperx, *dask_inputs)\n",
    "wait(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a777114f-b1e1-44ed-bc5d-ec89ab383e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da28c320-a49c-41e6-85e5-f73cc552b935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1757142857142857"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimated number of days to run whisperx over data set assuming ~1 minute per list recording\n",
    "n_sess = len(all_input_dirs[tag])\n",
    "n_lists = 24\n",
    "n_cores = 35\n",
    "n_sess * n_lists / (n_cores * 24 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655baf8f-31bc-48e7-b1a6-9cf4e811fcdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "annotate",
   "language": "python",
   "name": "annotate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
